{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def lgbm_f1score(X_train, y_train, X_test, y_test):\n",
    "    lgbm = LGBMClassifier(random_state=2022)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    y_pred = lgbm.predict(X_test)\n",
    "    print(f\"f1_score: {f1_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/raw/train_data.csv')\n",
    "y = pd.read_csv('../data/raw/train_labels.csv')\n",
    "y = y.replace(-1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), stratify=y, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgbm_f1score(X_train, y_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(clip=True, feature_range=(-1.0, 1.0))\n",
    "scaler.fit(X_train)\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgbm_f1score(X_train, y_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgbm_f1score(X_train, y_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"kpca\", KernelPCA()),\n",
    "                     (\"rf\", LGBMClassifier())])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__n_components\": [20, 50, 70, 90 , 120, 200],\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 2),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\", \"linear\", \"poly\"]\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring=make_scorer(f1_score, average='micro'), verbose=10)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'kpca__gamma': 0.03, 'kpca__n_components': 200}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9962953698556811"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "kpca = KernelPCA(n_components=90, gamma=0.03, kernel='linear')\n",
    "kpca.fit(X_train, y_test)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), stratify=y, test_size=0.2, shuffle=True)\n",
    "X_train = kpca.transform(X_train)\n",
    "X_test = kpca.transform(X_test)\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=2022)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "print(f\"f1_score: {f1_score(y_test, y_pred)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, ..., 0, 0, 0])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_f1score(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.30trial/s, best loss: 0.23888888888888893]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.69s/trial, best loss: 0.23888888888888893]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.24trial/s, best loss: 0.11111111111111116]\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.63s/trial, best loss: 0.11111111111111116]\n",
      "100%|██████████| 5/5 [00:00<00:00,  2.35trial/s, best loss: 0.04629629629629628]\n",
      "100%|██████████| 6/6 [00:00<00:00, 14.62trial/s, best loss: 0.04629629629629628]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.54s/trial, best loss: 0.04629629629629628]\n",
      "100%|██████████| 8/8 [00:00<00:00,  6.35trial/s, best loss: 0.04629629629629628]\n",
      "100%|██████████| 9/9 [00:23<00:00, 23.83s/trial, best loss: 0.04629629629629628]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.43s/trial, best loss: 0.04629629629629628]\n",
      "[09:20:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 11/11 [00:07<00:00,  7.41s/trial, best loss: 0.04629629629629628]\n",
      "100%|██████████| 12/12 [00:01<00:00,  1.95s/trial, best loss: 0.04629629629629628]\n",
      "100%|██████████| 13/13 [00:04<00:00,  4.97s/trial, best loss: 0.04629629629629628]\n",
      "100%|██████████| 14/14 [00:00<00:00,  1.41trial/s, best loss: 0.04629629629629628]\n",
      "100%|██████████| 15/15 [00:33<00:00, 33.23s/trial, best loss: 0.00462962962962965]\n",
      "[09:21:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 16/16 [00:06<00:00,  6.79s/trial, best loss: 0.00462962962962965]\n",
      "[09:21:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 17/17 [00:32<00:00, 32.42s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 18/18 [00:00<00:00,  2.32trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 19/19 [00:00<00:00,  2.75trial/s, best loss: 0.00462962962962965]\n",
      "[09:22:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 20/20 [00:32<00:00, 32.93s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 21/21 [00:02<00:00,  2.41s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 22/22 [00:12<00:00, 12.09s/trial, best loss: 0.00462962962962965]\n",
      "[09:22:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 23/23 [00:31<00:00, 31.95s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 24/24 [00:00<00:00,  3.10trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 25/25 [01:00<00:00, 60.09s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.34s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 27/27 [00:00<00:00, 14.47trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 28/28 [00:07<00:00,  7.94s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 29/29 [00:21<00:00, 21.09s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 30/30 [00:00<00:00,  6.22trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 31/31 [00:01<00:00,  1.78s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 32/32 [00:05<00:00,  5.24s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 33/33 [00:00<00:00,  8.48trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.52s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 35/35 [00:00<00:00,  4.85trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.99s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 37/37 [00:00<00:00, 16.29trial/s, best loss: 0.00462962962962965]\n",
      "100%|██████████| 38/38 [00:01<00:00,  1.06s/trial, best loss: 0.00462962962962965]\n",
      "100%|██████████| 39/39 [00:00<00:00,  1.58trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 40/40 [00:00<00:00,  3.59trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 41/41 [00:00<00:00,  5.04trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 42/42 [00:00<00:00,  1.64trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 43/43 [00:13<00:00, 13.51s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 44/44 [00:00<00:00,  6.28trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 45/45 [00:00<00:00,  2.07trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 46/46 [01:00<00:00, 60.05s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 47/47 [00:00<00:00,  1.88trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 48/48 [00:01<00:00,  1.09s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 49/49 [00:08<00:00,  8.38s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 50/50 [00:00<00:00,  1.23trial/s, best loss: 0.0018518518518518823]\n",
      "[09:26:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 51/51 [00:04<00:00,  4.00s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 52/52 [00:01<00:00,  1.90s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 53/53 [00:17<00:00, 17.55s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 54/54 [00:00<00:00, 12.57trial/s, best loss: 0.0018518518518518823]\n",
      "[09:26:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 55/55 [00:13<00:00, 13.37s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 56/56 [00:00<00:00,  4.44trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 57/57 [00:03<00:00,  3.99s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 58/58 [00:00<00:00,  2.51trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 59/59 [00:00<00:00,  1.21trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 60/60 [00:00<00:00,  1.88trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 61/61 [00:00<00:00,  5.59trial/s, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 62/62 [00:04<00:00,  4.25s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 63/63 [00:33<00:00, 33.94s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 64/64 [00:04<00:00,  4.25s/trial, best loss: 0.0018518518518518823]\n",
      "100%|██████████| 65/65 [00:00<00:00,  2.59trial/s, best loss: 0.0]\n",
      "100%|██████████| 66/66 [00:00<00:00,  5.65trial/s, best loss: 0.0]\n",
      "100%|██████████| 67/67 [00:00<00:00,  6.53trial/s, best loss: 0.0]\n",
      "[09:28:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 68/68 [00:24<00:00, 24.96s/trial, best loss: 0.0]\n",
      "100%|██████████| 69/69 [00:00<00:00, 16.29trial/s, best loss: 0.0]\n",
      "100%|██████████| 70/70 [00:00<00:00, 14.75trial/s, best loss: 0.0]\n",
      "100%|██████████| 71/71 [00:18<00:00, 18.44s/trial, best loss: 0.0]\n",
      "100%|██████████| 72/72 [00:00<00:00,  5.87trial/s, best loss: 0.0]\n",
      "100%|██████████| 73/73 [00:01<00:00,  1.29s/trial, best loss: 0.0]\n",
      "100%|██████████| 74/74 [00:00<00:00,  6.15trial/s, best loss: 0.0]\n",
      "100%|██████████| 75/75 [00:01<00:00,  1.19s/trial, best loss: 0.0]\n",
      "100%|██████████| 76/76 [00:01<00:00,  1.91s/trial, best loss: 0.0]\n",
      "100%|██████████| 77/77 [00:01<00:00,  1.94s/trial, best loss: 0.0]\n",
      "[09:28:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 78/78 [00:19<00:00, 19.84s/trial, best loss: 0.0]\n",
      "100%|██████████| 79/79 [00:00<00:00,  6.93trial/s, best loss: 0.0]\n",
      "100%|██████████| 80/80 [00:02<00:00,  2.07s/trial, best loss: 0.0]\n",
      "[09:29:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 81/81 [00:23<00:00, 23.76s/trial, best loss: 0.0]\n",
      "100%|██████████| 82/82 [00:00<00:00, 13.02trial/s, best loss: 0.0]\n",
      "100%|██████████| 83/83 [00:01<00:00,  1.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 84/84 [00:01<00:00,  1.02s/trial, best loss: 0.0]\n",
      "100%|██████████| 85/85 [00:00<00:00,  6.31trial/s, best loss: 0.0]\n",
      "100%|██████████| 86/86 [00:02<00:00,  2.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 87/87 [00:10<00:00, 10.97s/trial, best loss: 0.0]\n",
      "100%|██████████| 88/88 [00:11<00:00, 11.07s/trial, best loss: 0.0]\n",
      "100%|██████████| 89/89 [00:00<00:00,  2.44trial/s, best loss: 0.0]\n",
      "100%|██████████| 90/90 [00:08<00:00,  8.69s/trial, best loss: 0.0]\n",
      "100%|██████████| 91/91 [00:00<00:00, 12.07trial/s, best loss: 0.0]\n",
      "100%|██████████| 92/92 [00:00<00:00, 13.59trial/s, best loss: 0.0]\n",
      "100%|██████████| 93/93 [00:00<00:00,  1.12trial/s, best loss: 0.0]\n",
      "100%|██████████| 94/94 [00:00<00:00,  3.09trial/s, best loss: 0.0]\n",
      "100%|██████████| 95/95 [00:00<00:00,  5.28trial/s, best loss: 0.0]\n",
      "100%|██████████| 96/96 [00:00<00:00, 14.93trial/s, best loss: 0.0]\n",
      "100%|██████████| 97/97 [00:00<00:00, 10.09trial/s, best loss: 0.0]\n",
      "100%|██████████| 98/98 [00:00<00:00,  9.06trial/s, best loss: 0.0]\n",
      "100%|██████████| 99/99 [00:01<00:00,  1.24s/trial, best loss: 0.0]\n",
      "100%|██████████| 100/100 [00:03<00:00,  3.28s/trial, best loss: 0.0]\n",
      "[09:30:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 101/101 [01:00<00:00, 60.10s/trial, best loss: 0.0]\n",
      "100%|██████████| 102/102 [00:04<00:00,  4.24s/trial, best loss: 0.0]\n",
      "100%|██████████| 103/103 [00:00<00:00, 13.93trial/s, best loss: 0.0]\n",
      "100%|██████████| 104/104 [00:03<00:00,  3.68s/trial, best loss: 0.0]\n",
      "[09:31:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 105/105 [00:26<00:00, 26.46s/trial, best loss: 0.0]\n",
      "100%|██████████| 106/106 [00:04<00:00,  4.66s/trial, best loss: 0.0]\n",
      "100%|██████████| 107/107 [00:05<00:00,  5.67s/trial, best loss: 0.0]\n",
      "100%|██████████| 108/108 [00:03<00:00,  3.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 109/109 [00:00<00:00,  2.20trial/s, best loss: 0.0]\n",
      "100%|██████████| 110/110 [00:15<00:00, 15.15s/trial, best loss: 0.0]\n",
      "100%|██████████| 111/111 [00:00<00:00,  2.50trial/s, best loss: 0.0]\n",
      "100%|██████████| 112/112 [00:01<00:00,  1.43s/trial, best loss: 0.0]\n",
      "100%|██████████| 113/113 [00:05<00:00,  5.50s/trial, best loss: 0.0]\n",
      "[09:32:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 114/114 [00:54<00:00, 54.77s/trial, best loss: 0.0]\n",
      "100%|██████████| 115/115 [00:05<00:00,  5.87s/trial, best loss: 0.0]\n",
      "100%|██████████| 116/116 [00:03<00:00,  3.94s/trial, best loss: 0.0]\n",
      "100%|██████████| 117/117 [00:09<00:00,  9.33s/trial, best loss: 0.0]\n",
      "[09:33:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 118/118 [00:09<00:00,  9.90s/trial, best loss: 0.0]\n",
      "100%|██████████| 119/119 [00:00<00:00, 11.21trial/s, best loss: 0.0]\n",
      "100%|██████████| 120/120 [00:00<00:00,  1.55trial/s, best loss: 0.0]\n",
      "100%|██████████| 121/121 [00:31<00:00, 31.05s/trial, best loss: 0.0]\n",
      "100%|██████████| 122/122 [00:00<00:00,  9.83trial/s, best loss: 0.0]\n",
      "100%|██████████| 123/123 [00:03<00:00,  3.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 124/124 [00:02<00:00,  2.11s/trial, best loss: 0.0]\n",
      "100%|██████████| 125/125 [00:00<00:00,  1.58trial/s, best loss: 0.0]\n",
      "100%|██████████| 126/126 [00:00<00:00,  5.56trial/s, best loss: 0.0]\n",
      "100%|██████████| 127/127 [00:00<00:00,  3.06trial/s, best loss: 0.0]\n",
      "100%|██████████| 128/128 [00:00<00:00, 13.21trial/s, best loss: 0.0]\n",
      "[09:34:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 129/129 [00:26<00:00, 26.08s/trial, best loss: 0.0]\n",
      "100%|██████████| 130/130 [00:00<00:00, 14.84trial/s, best loss: 0.0]\n",
      "100%|██████████| 131/131 [00:00<00:00,  1.43trial/s, best loss: 0.0]\n",
      "100%|██████████| 132/132 [00:00<00:00,  1.10trial/s, best loss: 0.0]\n",
      "100%|██████████| 133/133 [00:09<00:00,  9.26s/trial, best loss: 0.0]\n",
      "100%|██████████| 134/134 [00:00<00:00,  7.33trial/s, best loss: 0.0]\n",
      "100%|██████████| 135/135 [00:00<00:00,  1.19trial/s, best loss: 0.0]\n",
      "100%|██████████| 136/136 [00:08<00:00,  8.55s/trial, best loss: 0.0]\n",
      "100%|██████████| 137/137 [00:06<00:00,  6.48s/trial, best loss: 0.0]\n",
      "100%|██████████| 138/138 [00:00<00:00,  4.63trial/s, best loss: 0.0]\n",
      "100%|██████████| 139/139 [00:00<00:00, 14.31trial/s, best loss: 0.0]\n",
      "[09:35:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 140/140 [00:12<00:00, 12.54s/trial, best loss: 0.0]\n",
      "100%|██████████| 141/141 [00:00<00:00,  1.17trial/s, best loss: 0.0]\n",
      "100%|██████████| 142/142 [00:00<00:00,  1.11trial/s, best loss: 0.0]\n",
      "100%|██████████| 143/143 [00:02<00:00,  2.29s/trial, best loss: 0.0]\n",
      "100%|██████████| 144/144 [00:00<00:00,  5.43trial/s, best loss: 0.0]\n",
      "100%|██████████| 145/145 [00:01<00:00,  1.60s/trial, best loss: 0.0]\n",
      "[09:35:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 146/146 [00:37<00:00, 37.73s/trial, best loss: 0.0]\n",
      "100%|██████████| 147/147 [00:04<00:00,  4.74s/trial, best loss: 0.0]\n",
      "100%|██████████| 148/148 [00:01<00:00,  1.45s/trial, best loss: 0.0]\n",
      "100%|██████████| 149/149 [00:01<00:00,  1.56s/trial, best loss: 0.0]\n",
      "100%|██████████| 150/150 [00:16<00:00, 16.45s/trial, best loss: 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'learner': KNeighborsClassifier(algorithm='brute', leaf_size=39, metric='manhattan',\n                      n_jobs=1, n_neighbors=7, p=3.198659538429792,\n                      weights='distance'),\n 'preprocs': (Normalizer(norm='l1'),),\n 'ex_preprocs': ()}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, lightgbm_classification\n",
    "\n",
    "estim = HyperoptEstimator(classifier=any_classifier('cla'), preprocessing=any_preprocessing('pre'),max_evals=150,trial_timeout=60)\n",
    "estim.fit(X_train, y_train)\n",
    "estim.best_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from Normalizer\n",
    "\n",
    "lgbm = KNeighborsClassifier(algorithm='brute', leaf_size=39, metric='manhattan',\n",
    "                      n_jobs=1, n_neighbors=7, p=3.198659538429792,\n",
    "                      weights='distance')\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "print(f\"f1_score: {f1_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "pca_99 = PCA(n_components=100)\n",
    "fit = pca_99.fit(X_train)\n",
    "X_train = fit.transform(X_train)\n",
    "X_test = fit.transform(X_test)\n",
    "\n",
    "#tsne = TSNE(init='pca', n_components=2, learning_rate=100)\n",
    "#X_train = tsne.fit_transform(X_train)\n",
    "#X_test = tsne.fit_transform(X_test)\n",
    "\n",
    "lgbm = KNeighborsClassifier(algorithm='brute', leaf_size=39, metric='manhattan',\n",
    "                      n_jobs=1, n_neighbors=7, p=3.198659538429792,\n",
    "                      weights='distance')\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "print(f\"f1_score: {f1_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}